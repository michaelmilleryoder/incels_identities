{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bf2081b-bfa7-410a-93b0-596f75d2d34c",
   "metadata": {},
   "source": [
    "Find central users from the user x user (shared thread) network and characterize their behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed349ee-1ea1-48ce-b569-bf669e60eea0",
   "metadata": {},
   "source": [
    "# Load central users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6120b8b-51d5-45b7-b2fb-072a919184a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6819 entries, Transcended Trucel to rot099\n",
      "Data columns (total 2 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   eigenvectorCentrality  6819 non-null   float64\n",
      " 1   totalDegreeCentrality  6819 non-null   float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 159.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Measure</th>\n",
       "      <th>eigenvectorCentrality</th>\n",
       "      <th>totalDegreeCentrality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Transcended Trucel</th>\n",
       "      <td>0.000396</td>\n",
       "      <td>2.797220e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItsNotADream</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.959646e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAAAAAAAAAcel</th>\n",
       "      <td>0.107865</td>\n",
       "      <td>1.865163e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amerihiki</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>6.461526e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deleted member 7448</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>8.474116e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Measure              eigenvectorCentrality  totalDegreeCentrality\n",
       "Transcended Trucel                0.000396           2.797220e-06\n",
       "ItsNotADream                      0.000009           1.959646e-07\n",
       "AAAAAAAAAAAcel                    0.107865           1.865163e-04\n",
       "Amerihiki                         0.000002           6.461526e-08\n",
       "Deleted member 7448               0.000020           8.474116e-07"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load central users (calculated from ORA)\n",
    "import pandas as pd\n",
    "\n",
    "path = '../output/incels_is_centrality_measures.csv'\n",
    "central = pd.read_csv(path, index_col=0).drop(columns=['Input networks', 'Input nodesets', 'Input parameters']).transpose()\n",
    "central.info()\n",
    "\n",
    "central.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b155848e-a871-4c04-90b6-9d4ab5972fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6819\n",
      "340\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Measure</th>\n",
       "      <th>eigenvectorCentrality</th>\n",
       "      <th>totalDegreeCentrality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Liszt</th>\n",
       "      <td>0.000135</td>\n",
       "      <td>1.965215e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>squirrelsonfire2</th>\n",
       "      <td>0.000133</td>\n",
       "      <td>9.353180e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Measure           eigenvectorCentrality  totalDegreeCentrality\n",
       "Liszt                          0.000135           1.965215e-06\n",
       "squirrelsonfire2               0.000133           9.353180e-07"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(central))\n",
    "top = int(len(central)/20)\n",
    "print(top)\n",
    "highest_eigen = central.sort_values('eigenvectorCentrality', ascending=False).iloc[:top]\n",
    "highest_eigen.head(10)\n",
    "\n",
    "highest_eigen.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b2e6401-1381-4fab-b675-7fb6377ac733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6479"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest = central[~central.index.isin(highest_eigen.index)]\n",
    "len(rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4399520f-5fd5-4c2c-b416-0685517a9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph distributions of centrality measures\n",
    "import plotly.express as px\n",
    "\n",
    "selected = central.sort_values('totalDegreeCentrality', ascending=False).head(100)\n",
    "px.bar(selected, x=selected.index, y='totalDegreeCentrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7421f07-e010-40d3-8162-1b6f8f7c3115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph distributions of centrality measures\n",
    "import plotly.express as px\n",
    "\n",
    "selected = central.sort_values('eigenvectorCentrality', ascending=False).head(100)\n",
    "px.bar(selected, x=selected.index, y='eigenvectorCentrality')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95178cce-e6e6-4a02-ae08-0cb6a1ea41da",
   "metadata": {},
   "source": [
    "# Compare cel variants in usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55214fbf-533b-4c9e-9e8d-c05f9a401bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 ( 15.88%) cel names in top\n",
      "1048 ( 16.18%) cel names in bottom\n"
     ]
    }
   ],
   "source": [
    "# Extract cel variants from top users vs others\n",
    "topcel = [name for name in highest_eigen.index if 'cel' in name]\n",
    "print(f'{len(topcel)} ({len(topcel)/len(highest_eigen): .2%}) cel names in top')\n",
    "bottomcel = [name for name in rest.index if 'cel' in name]\n",
    "print(f'{len(bottomcel)} ({len(bottomcel)/len(rest): .2%}) cel names in bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e05c9ee-23de-4a15-8196-d46f4649c8b9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amphetaminecel',\n",
       " 'Cowcel',\n",
       " 'SillyTruecel',\n",
       " 'AAAAAAAAAAAcel',\n",
       " 'Animecel2D',\n",
       " 'Based-nearcel',\n",
       " 'Ghoulcel',\n",
       " 'Diocel',\n",
       " 'Zettacel',\n",
       " 'Incellectual',\n",
       " 'Lookscel',\n",
       " 'ItsOver4cel',\n",
       " 'soymonkcel',\n",
       " 'Sadandangrycel',\n",
       " 'Damo the incel',\n",
       " 'Ritalincel',\n",
       " 'Idlevillagercel',\n",
       " 'Cheesecel',\n",
       " 'Caesercel',\n",
       " 'Uglychincel',\n",
       " 'JosefMengelecel',\n",
       " 'PPEcel',\n",
       " 'Tiredpoorcel',\n",
       " 'angrycurrycel',\n",
       " 'croatincel',\n",
       " 'SuperSaiyanGymcel',\n",
       " 'Daydreamincel',\n",
       " 'gymletethnicel',\n",
       " 'Templarcel421',\n",
       " 'BraincelsRefugee',\n",
       " 'SergeantIncel',\n",
       " 'JohnDcel',\n",
       " 'turbocuckcel_7000',\n",
       " 'DominicanDancecel91',\n",
       " 'gigacel123',\n",
       " 'Gyros_Pretcel',\n",
       " 'Transcended Trucel',\n",
       " 'speedtypingincel',\n",
       " 'HighTGymcel',\n",
       " 'IncelCream',\n",
       " 'Legendarywristcel',\n",
       " 'singleplayercel',\n",
       " 'stuttercel',\n",
       " 'kikecel',\n",
       " 'littlemanhikicel',\n",
       " 'SkinnyBaldcel',\n",
       " 'lonelycel69',\n",
       " 'EthnicelNL',\n",
       " 'Gymcelled',\n",
       " 'rightfulcel',\n",
       " 'crestfallencel',\n",
       " 'carticel',\n",
       " 'Bleachcel',\n",
       " 'Blackcel rigth wing']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topcel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc512c03-04bc-4254-b727-fce724f9c098",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ChronicPaincel',\n",
       " 'Blackpincel',\n",
       " 'Wizcel',\n",
       " 'dirtykombatcel',\n",
       " 'Massimo The Lonecel',\n",
       " 'Chileancel',\n",
       " 'Rambocel',\n",
       " 'Mentally lost cel',\n",
       " 'Hyperwristcel',\n",
       " 'Arabcel9',\n",
       " 'MScel',\n",
       " 'Legallyblindcel',\n",
       " 'guaucel',\n",
       " 'Wagiecel',\n",
       " 'TheIncredibleIncel',\n",
       " 'ghettocel',\n",
       " 'Cafecel',\n",
       " 'TheUltimateMarkcel',\n",
       " 'Mulattocel',\n",
       " 'codingcel',\n",
       " 'Currycel25',\n",
       " 'Incellio',\n",
       " 'Mountainbikecel',\n",
       " 'ThirdWorldcel',\n",
       " 'Arrogantcel',\n",
       " 'Philosophycel',\n",
       " 'andinocel',\n",
       " 'acnescarcel',\n",
       " 'Jockcel',\n",
       " 'UKhapacel',\n",
       " 'facepulling_incel',\n",
       " 'DBcel',\n",
       " 'startcel',\n",
       " 'Timecel',\n",
       " 'Limerencel',\n",
       " 'Gremlincel',\n",
       " 'Bagelcel',\n",
       " 'CopingGymcel',\n",
       " 'presidencel',\n",
       " 'TheMostAncientcel',\n",
       " 'DENSA_IQcel',\n",
       " 'toyotacel',\n",
       " 'Quasimodocel',\n",
       " 'Subhuman Currycel',\n",
       " 'fuckupcel',\n",
       " 'GermaniaIncelia',\n",
       " 'Greyandoldcel',\n",
       " 'Eschewcel',\n",
       " 'eurocel',\n",
       " 'TheRealChincel']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottomcel[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f15d3ba-987a-4129-9b71-96dce86fb7a7",
   "metadata": {},
   "source": [
    "# Compare identity group use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b00266b0-6518-4a22-ae8e-022e35edaf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6248230 entries, 0 to 6248229\n",
      "Data columns (total 11 columns):\n",
      " #   Column                            Dtype         \n",
      "---  ------                            -----         \n",
      " 0   type                              object        \n",
      " 1   forum                             object        \n",
      " 2   thread                            object        \n",
      " 3   username                          object        \n",
      " 4   date                              object        \n",
      " 5   content                           object        \n",
      " 6   parsed_date                       datetime64[ns]\n",
      " 7   content_orig                      object        \n",
      " 8   netmapper_identity_matches        object        \n",
      " 9   netmapper_identity_matches_spans  object        \n",
      " 10  actions_attributes                object        \n",
      "dtypes: datetime64[ns](1), object(10)\n",
      "memory usage: 524.4+ MB\n",
      "513\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13578886 entries, 0 to 6248229\n",
      "Data columns (total 12 columns):\n",
      " #   Column                            Dtype         \n",
      "---  ------                            -----         \n",
      " 0   type                              object        \n",
      " 1   forum                             object        \n",
      " 2   thread                            object        \n",
      " 3   username                          object        \n",
      " 4   date                              object        \n",
      " 5   content                           object        \n",
      " 6   parsed_date                       datetime64[ns]\n",
      " 7   content_orig                      object        \n",
      " 8   netmapper_identity_matches        object        \n",
      " 9   netmapper_identity_matches_spans  object        \n",
      " 10  actions_attributes                object        \n",
      " 11  identity_group                    object        \n",
      "dtypes: datetime64[ns](1), object(11)\n",
      "memory usage: 1.3+ GB\n"
     ]
    }
   ],
   "source": [
    "# Load data with extracted actions and attributes\n",
    "import pandas as pd\n",
    "\n",
    "path = '../../data/incels/processed_comments.pkl'\n",
    "data = pd.read_pickle(path)\n",
    "data.info()\n",
    "\n",
    "exp = data.explode('netmapper_identity_matches')\n",
    "# exp.info()\n",
    "\n",
    "# Group identities\n",
    "import json\n",
    "\n",
    "identity_groups_fpath = '../resources/identity_groups.json'\n",
    "with open(identity_groups_fpath, 'r') as f:\n",
    "    identity_groups = json.load(f)\n",
    "print(len(identity_groups))\n",
    "\n",
    "exp['identity_group'] = exp.netmapper_identity_matches.map(lambda x: identity_groups.get(x, x))\n",
    "exploded = exp.explode('identity_group') # Count intersectional mentions as a mention in each of their categories\n",
    "exploded.info()\n",
    "\n",
    "# samp = exploded.sample(int(1e6))\n",
    "# gped = samp.groupby('identity_group')\n",
    "gped = exploded.groupby('identity_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6bfa55-76fc-4aba-9a36-8540cde37910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3052056\n",
      "3184199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7850586"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_data = data[data.username.isin(highest_eigen.index)]\n",
    "rest_data = data[data.username.isin(rest.index)]\n",
    "print(len(top_data))\n",
    "print(len(rest_data))\n",
    "\n",
    "top_exploded = exploded[exploded['username'].isin(highest_eigen.index)]\n",
    "len(top_exploded)\n",
    "\n",
    "rest_exploded = exploded[exploded['username'].isin(rest.index)]\n",
    "len(rest_exploded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cad9dd-5dc4-4388-a664-c456273ef5b3",
   "metadata": {},
   "source": [
    "## Plot for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bbac66-df6a-49e2-ac05-1ecd2bdc0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_counts = gped['content'].count().sort_values(ascending=False)\n",
    "selected_gps = [gp for gp in gp_counts.index[:12].tolist() if gp not in ['women_girls_derogatory', 'men_boys_address', 'youth']] + ['truecels', 'fakecels']\n",
    "selected_gps\n",
    "\n",
    "# Distributions of identity group mentions\n",
    "top_counts = top_exploded.groupby('identity_group')['content'].count()\n",
    "rest_counts = rest_exploded.groupby('identity_group')['content'].count()\n",
    "# top_counts = top_counts[top_counts.index.isin(selected_gps)]/len(top_data)\n",
    "# rest_counts = rest_counts[rest_counts.index.isin(selected_gps)]/len(rest_data)\n",
    "top_counts = top_counts[top_counts.index.isin(selected_gps)]/top_counts.sum()\n",
    "rest_counts = rest_counts[rest_counts.index.isin(selected_gps)]/rest_counts.sum()\n",
    "top_counts\n",
    "\n",
    "counts = top_counts.to_frame(name='top')\n",
    "counts['rest'] = rest_counts\n",
    "# long = counts.reset_index().melt(id_vars='identity_group', value_vars=['top', 'rest'], var_name='user_group', value_name='mentions_per_post')\n",
    "long = counts.reset_index().melt(id_vars='identity_group', value_vars=['top', 'rest'], var_name='user_group', value_name='proportion_mentions')\n",
    "long\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "long['log_proportion_mentions'] = long['proportion_mentions'].map(lambda x: np.log(x))\n",
    "long\n",
    "\n",
    "custom_order = dict(reversed(el) for el in enumerate([\n",
    "    'women_girls', 'men_boys', 'asian_people', 'black_people', 'white_people', 'jews', 'lgbtq_people', \n",
    "    'mental_disabilities', 'incels', 'truecels', 'fakecels']))\n",
    "long = long.sort_values(['identity_group'], key=lambda x: x.map(custom_order))\n",
    "column_map = {'identity_group': 'Identity group', 'user_group': 'User group', 'proportion_mentions': 'Proportion of mentions',\n",
    "             'log_proportion_mentions': 'Log proportion of mentions'}\n",
    "formatted = long.rename(columns=column_map).replace({\n",
    "    'women_girls': 'Women',\n",
    "    'men_boys': 'Men',\n",
    "    'youth': 'Youth',\n",
    "    'mental_disabilities': 'Neurodiverse',\n",
    "    'lgbtq_people': 'LGBTQ+',\n",
    "    'asian_people': 'Asian',\n",
    "    'black_people': 'Black',\n",
    "    'white_people': 'White',\n",
    "    'jews': 'Jews',\n",
    "    'incels': 'Incels',\n",
    "    'truecels': 'Truecels',\n",
    "    'fakecels': 'Fakecels',\n",
    "})\n",
    "formatted\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.bar(formatted, x=column_map['identity_group'], y=column_map['proportion_mentions'], color=column_map['user_group'], barmode='group',\n",
    "            log_y=True, width=600, height=400)\n",
    "# fig = px.bar(formatted, x=column_map['identity_group'], y=column_map['log_proportion_mentions'], color=column_map['user_group'], barmode='group')\n",
    "fig.update_layout(xaxis_title=None)\n",
    "fig.write_image('../output/top5percent_eigen_identity_group_mentions.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b430893-f959-4663-8932-df79ad4a1a62",
   "metadata": {},
   "source": [
    "# Compare text with PMI\n",
    "Using top 5% eigenvector centrality as a label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71c77994-6684-459c-9265-783a31357a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['nihility', 'unsettling', 'Amphetaminecel', 'mNFwTJ3wz9', 'Cowcel',\n",
       "       'Idotms', 'SillyTruecel', 'schrodingercoper', 'Deleted member 29001',\n",
       "       'AAAAAAAAAAAcel',\n",
       "       ...\n",
       "       'Lolimancer', 'seija', 'System Restore', 'ReconElement',\n",
       "       'tooth monster', 'Reprobus', 'Anger', 'heroinfather', 'Liszt',\n",
       "       'squirrelsonfire2'],\n",
       "      dtype='object', length=340)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_eigen.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9a61373b-3db8-44b3-92e4-752008988681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False: 3196174, True: 3052056}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data with extracted actions and attributes\n",
    "data['top5percent_eigen_user'] = data.username.isin(highest_eigen.index)\n",
    "data.top5percent_eigen_user.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b56bd1be-bac5-41a8-91ea-5faa91a3d08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6248230 entries, 0 to 6248229\n",
      "Data columns (total 12 columns):\n",
      " #   Column                            Dtype         \n",
      "---  ------                            -----         \n",
      " 0   type                              object        \n",
      " 1   forum                             object        \n",
      " 2   thread                            object        \n",
      " 3   username                          object        \n",
      " 4   date                              object        \n",
      " 5   content                           object        \n",
      " 6   parsed_date                       datetime64[ns]\n",
      " 7   content_orig                      object        \n",
      " 8   netmapper_identity_matches        object        \n",
      " 9   netmapper_identity_matches_spans  object        \n",
      " 10  actions_attributes                object        \n",
      " 11  top5percent_eigen_user            bool          \n",
      "dtypes: bool(1), datetime64[ns](1), object(10)\n",
      "memory usage: 530.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.drop(columns=['top5_percent_eigen_user'], inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b6cee1ce-5f5e-484f-93da-1560390fdda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out for STM analysis\n",
    "outpath = '../../data/incels/processed_comments_user_info.jsonl'\n",
    "data[['username', 'top5percent_eigen_user', 'parsed_date', 'content']].to_json(outpath, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed55ca54-3e36-4e53-8e73-04316ec317b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9f33e807da40f99f89037750949fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6248230 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0          None\n",
       "1          None\n",
       "2          None\n",
       "3          None\n",
       "4          None\n",
       "           ... \n",
       "6248225    None\n",
       "6248226    None\n",
       "6248227    None\n",
       "6248228    None\n",
       "6248229    None\n",
       "Name: content, Length: 6248230, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count needed totals\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "cooccurrences = {} # relation: {(user_group, word): n_times_co-occurs, ...}\n",
    "word_freqs = {} # relation: {word: n_times_occurs_anywhere}\n",
    "total_combinations = Counter() # total # label-word matches (total words)\n",
    "\n",
    "# First pass to get total word counts\n",
    "freqs = Counter()\n",
    "data.content.str.split().progress_apply(freqs.update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "57e6d373-33b6-425b-a05e-5f451d246578",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " 'i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "\n",
    "stops = list(string.punctuation) + nltk.corpus.stopwords.words('english')\n",
    "stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "31070251-6a99-47d0-a7bf-689c5483a476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{False: 3196174, True: 3052056}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter by \n",
    "# freq_threshold = 1000\n",
    "freq_threshold = 200\n",
    "word_freqs = {term: count for term, count in freqs.items() if count >= freq_threshold and term not in stops}\n",
    "print(len(word_freqs))\n",
    "label_freqs = data.top5percent_eigen_user.value_counts().to_dict()\n",
    "label_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3cd558aa-ea5a-45bf-95b0-f9979c5638fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6248230"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "828cf10e-ff91-45f1-b532-98a3287ad84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988a183fb18142c4ad718455b824f3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6248230 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0          None\n",
       "1          None\n",
       "2          None\n",
       "3          None\n",
       "4          None\n",
       "           ... \n",
       "6248225    None\n",
       "6248226    None\n",
       "6248227    None\n",
       "6248228    None\n",
       "6248229    None\n",
       "Length: 6248230, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second pass to count cooccurrences (and filter by frequency)\n",
    "cooccurrences = Counter()\n",
    "\n",
    "def build_cooccurrences(row):\n",
    "    cooccurrences.update({(row['top5percent_eigen_user'], wd): count for wd, count in Counter(row['content'].lower().split()).items() if wd in word_freqs})\n",
    "\n",
    "data.progress_apply(build_cooccurrences, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "403a4f30-6294-46ba-991d-757d52ebc20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out cooccurrences since it took awhile\n",
    "import pickle\n",
    "\n",
    "path = '../tmp/top5percent_eigen_user_cooccurrences.pkl'\n",
    "with open(path, 'wb') as f:\n",
    "    pickle.dump(cooccurrences, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4076e7c4-9c8f-4db7-aa48-fa9be0d16db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_combinations = sum(word_freqs.values()) # total #words\n",
    "    \n",
    "from operator import itemgetter\n",
    "import math\n",
    "import pdb\n",
    "\n",
    "def pmi(words, label_freqs, word_freqs, cooccurrences, n):\n",
    "    \"\"\" Args:\n",
    "            words: query tuple of (label, word)\n",
    "            label_freqs: dict of label: count\n",
    "            word_freqs: dict of word: count\n",
    "            cooccurrences: dict of (label, word): count\n",
    "            n: number of possible occurrences (number of words or bigrams in the doc)\n",
    "    \"\"\"\n",
    "    numerator = n * cooccurrences[words]\n",
    "    if numerator == 0:\n",
    "        return 0\n",
    "    denominator = label_freqs[words[0]] * word_freqs[words[1]]\n",
    "    return math.log(numerator/denominator, 2)\n",
    "\n",
    "def npmi(words, label_freqs, word_freqs, cooccurrences, n):\n",
    "    \"\"\" Normalized pointwise mutual information\n",
    "        Args:\n",
    "            words: query tuple of (label, word)\n",
    "            label_freqs: dict of label: count\n",
    "            word_freqs: dict of word: count\n",
    "            cooccurrences: dict of (label, word): count\n",
    "            n: number of possible occurrences (number of words or bigrams in the doc)\n",
    "    \"\"\"\n",
    "    numerator = pmi(words, label_freqs, word_freqs, cooccurrences, n)\n",
    "    denominator = -1 * math.log(cooccurrences[words]/n, 2)\n",
    "    return numerator/denominator\n",
    "\n",
    "def pmi2(words, label_freqs, word_freqs, cooccurrences, n):\n",
    "    return pmik(words, label_freqs, word_freqs, cooccurrences, n, 2)\n",
    "\n",
    "def pmi3(words, label_freqs, word_freqs, cooccurrences, n):\n",
    "    return pmik(words, label_freqs, word_freqs, cooccurrences, n, 3)\n",
    "\n",
    "def pmik(words, label_freqs, word_freqs, cooccurrences, n, k):\n",
    "    \"\"\" Args:\n",
    "            words: query tuple of (label, word)\n",
    "            label_freqs: dict of label: count\n",
    "            word_freqs: dict of word: count\n",
    "            cooccurrences: dict of (label, word): count\n",
    "            n: number of possible occurrences (number of words or bigrams in the doc)\n",
    "            k: type of pmik/exponent to use (for example 2 for pmi2 or 3 for pmi3)\n",
    "    \"\"\"\n",
    "    numerator = (cooccurrences[words]/n) ** k\n",
    "    denominator = (label_freqs[words[0]]/n) * (word_freqs[words[1]]/n)\n",
    "    return math.log(numerator/denominator, 2)\n",
    "\n",
    "def top_pmi(word, label_freqs, word_freqs, cooccurrences, n, calculation='pmi'):\n",
    "    \"\"\" \n",
    "            words: query tuple of (label, word)\n",
    "            label_freqs: dict of label: count\n",
    "            word_freqs: dict of word: count\n",
    "            cooccurrences: dict of (label, word): count\n",
    "            n: number of possible occurrences (number of words or bigrams in the doc)\n",
    "            calculation: type of pmi to run out of {'pmi', 'npmi', 'pmi2', 'pmi3'}\n",
    "    \"\"\"\n",
    "    # Returns top co-occurring words with a specified word based on PMI\n",
    "    fn = globals()[calculation]\n",
    "    \n",
    "    cooccurring_words = []\n",
    "    \n",
    "    pairs = [pair for pair in cooccurrences.keys() if word in pair and pair != (word, word)]  # all words that co-occur\n",
    "    \n",
    "    for pair in pairs:\n",
    "        other_word = [w for w in pair if w != word][0]\n",
    "        cooccurring_words.append((other_word, fn(pair, label_freqs, word_freqs, cooccurrences, n)))\n",
    "        \n",
    "    return sorted(cooccurring_words, key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b6a9a4c1-a510-464f-bda4-747ede5d2646",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True: tbh, view, women, think, fuck, good, shit, want, know, attachment, never, men, time, fucking, see, man, incel, chad, life, really, make, foids, much, sex, white, say, jfl, way, got, bro, us, cope, yes\n",
      "\n",
      "False\n",
      "False: women, think, men, good, chad, want, fuck, shit, life, know, fucking, never, incel, time, white, much, make, see, look, really, sex, incels, us, ugly, way, foids, guy, got, man, looks, say, guys\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at PMI3 for identity group labels (freq threshold 100)\n",
    "calculation = 'pmi3'\n",
    "\n",
    "more_stops = ['still', 'could', 'go', 'also', \"n't\", \"'s\", 'like', 'would', 'get', 'nt', 'even', 'people', 'one', \"'m\", \"'re\", \"ca\", '...', 'nan', \"'ve\"] # also copy above\n",
    "\n",
    "for top in [True, False]:\n",
    "    print(top)\n",
    "    outstring = ', '.join([el[0] for el in top_pmi(top, label_freqs, word_freqs, cooccurrences, total_combinations, calculation=calculation)[:50] if el[0] not in more_stops])\n",
    "    print(f'{top}: {outstring}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
