{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d40512b7-31df-45f9-95f0-f0992666ebb7",
   "metadata": {},
   "source": [
    "# Dependency parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f786421-5d75-478e-b6a5-1db964f094d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6248230 entries, 0 to 6248229\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Dtype         \n",
      "---  ------                      -----         \n",
      " 0   type                        object        \n",
      " 1   forum                       object        \n",
      " 2   thread                      object        \n",
      " 3   username                    object        \n",
      " 4   date                        object        \n",
      " 5   content                     object        \n",
      " 6   parsed_date                 datetime64[ns]\n",
      " 7   content_orig                object        \n",
      " 8   netmapper_identity_matches  object        \n",
      "dtypes: datetime64[ns](1), object(8)\n",
      "memory usage: 429.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load data with identity term matches extracted, tokenized\n",
    "import pandas as pd\n",
    "\n",
    "path = '../../data/incels/processed_comments.pkl'\n",
    "# path = '../data/white_supremacist_identities.pkl'\n",
    "data = pd.read_pickle(path)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "101ae0ab-1b43-475f-a939-97129093328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f24f326-600c-4c4b-9889-c2d254fb6ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>forum</th>\n",
       "      <th>thread</th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>parsed_date</th>\n",
       "      <th>content_orig</th>\n",
       "      <th>netmapper_identity_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>COMMENT</td>\n",
       "      <td>001-MustReadContent</td>\n",
       "      <td>0000014-Itssosadthatwereplacesoc</td>\n",
       "      <td>THE TRUE HONKLER</td>\n",
       "      <td>Nov 20, 2020</td>\n",
       "      <td>frothysolutions said : do we ? in order to have this as a replacement for socializing , we have to want to be here . fag we were forced here by foids and lack of any other choice</td>\n",
       "      <td>2020-11-20</td>\n",
       "      <td>FrothySolutions said: Do we? In order to have this as a replacement for socializing, we have to want to be here. fag we were forced here by foids and lack of any other choice</td>\n",
       "      <td>[fag]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type                forum                            thread  \\\n",
       "12  COMMENT  001-MustReadContent  0000014-Itssosadthatwereplacesoc   \n",
       "\n",
       "            username          date  \\\n",
       "12  THE TRUE HONKLER  Nov 20, 2020   \n",
       "\n",
       "                                                                                                                                                                               content  \\\n",
       "12  frothysolutions said : do we ? in order to have this as a replacement for socializing , we have to want to be here . fag we were forced here by foids and lack of any other choice   \n",
       "\n",
       "   parsed_date  \\\n",
       "12  2020-11-20   \n",
       "\n",
       "                                                                                                                                                                      content_orig  \\\n",
       "12  FrothySolutions said: Do we? In order to have this as a replacement for socializing, we have to want to be here. fag we were forced here by foids and lack of any other choice   \n",
       "\n",
       "   netmapper_identity_matches  \n",
       "12                      [fag]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp = data[data.netmapper_identity_matches.map(lambda x: len(x) > 0)].head(1)\n",
    "samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fdf8b07-4c34-4481-9b12-4ef2dc8e42b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "test = test.loc[12, 'content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fee9c6f-5541-4ec2-9e4e-e081ba8ad863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frothysolutions said : do we ? in order to have this as a replacement for socializing , we have to want to be here . fag we were forced here by foids and lack of any other choice"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(test)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d9e447d-3986-4402-92ed-5cfa796e233e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nsubj',\n",
       " 'ROOT',\n",
       " 'punct',\n",
       " 'xcomp',\n",
       " 'nsubj',\n",
       " 'punct',\n",
       " 'prep',\n",
       " 'pobj',\n",
       " 'aux',\n",
       " 'acl',\n",
       " 'dobj',\n",
       " 'prep',\n",
       " 'det',\n",
       " 'pobj',\n",
       " 'prep',\n",
       " 'pobj',\n",
       " 'punct',\n",
       " 'nsubj',\n",
       " 'ROOT',\n",
       " 'aux',\n",
       " 'xcomp',\n",
       " 'aux',\n",
       " 'xcomp',\n",
       " 'advmod',\n",
       " 'punct',\n",
       " 'intj',\n",
       " 'nsubjpass',\n",
       " 'auxpass',\n",
       " 'ROOT',\n",
       " 'advmod',\n",
       " 'agent',\n",
       " 'pobj',\n",
       " 'cc',\n",
       " 'conj',\n",
       " 'prep',\n",
       " 'det',\n",
       " 'amod',\n",
       " 'pobj']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse = [tok.dep_ for tok in doc]\n",
    "parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3fdb563-550d-47ca-bdc1-184f6322a5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'intj'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse[tok_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58f8955c-a559-47b4-8cf4-4c96e6988ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forced"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tok.head for tok in doc][tok_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0253340d-523b-415c-b977-756a1be09d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fag': {'actions': [], 'attributes': []}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Match extracted identities to tokens\n",
    "from collections import defaultdict\n",
    "\n",
    "actions_attributes = {} # identity: {'actions': [actions], {'attributes': [attributes]} # replace with separate columns of attributes and actions in exploded df\n",
    "identity_ctr = defaultdict(int) # keep track of how many of this identity I've seen\n",
    "\n",
    "for identity in samp.loc[12, 'netmapper_identity_matches']:\n",
    "    \n",
    "    # Get identity mention locations\n",
    "    mention_idx = [i for i, tok in enumerate(doc) if tok.text==identity]\n",
    "    tok_idx = mention_idx[identity_ctr[identity]]\n",
    "    \n",
    "    # Verbs where identity term was the subject\n",
    "    verbs_subj = [tok.head.text for tok in doc if tok.i==tok_idx \\\n",
    "        in mention_idx and (tok.dep_=='nsubj' or tok.dep_=='agent')]\n",
    "\n",
    "    # Verbs where identity term was the object\n",
    "    verbs_obj = [tok.head.text for tok in doc if tok.i==tok_idx and \\\n",
    "        (tok.dep_=='dobj' or tok.dep_=='nsubjpass' or \\\n",
    "        tok.dep_=='dative' or tok.dep_=='pobj')]\n",
    "\n",
    "    # Adjectives that describe the identity term\n",
    "    adjs = [tok.text.lower() for tok in doc if tok.head.i == tok_idx and \\\n",
    "        (tok.dep_=='amod' or tok.dep_=='appos' or \\\n",
    "        tok.dep_=='nsubj' or tok.dep_=='nmod')] \\\n",
    "        + [tok.text.lower() for tok in doc if tok.dep_=='attr' and \\\n",
    "            (tok.head.text=='is' or tok.head.text=='was') and \\\n",
    "           any([c.i==tok_idx for c in tok.head.children])]\n",
    "    \n",
    "    actions_attributes[identity] = {'actions': verbs_subj + verbs_obj, 'attributes': adjs}\n",
    "    identity_ctr[identity] += 1\n",
    "    \n",
    "actions_attributes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
