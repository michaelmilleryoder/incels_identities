{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d40512b7-31df-45f9-95f0-f0992666ebb7",
   "metadata": {},
   "source": [
    "# Dependency parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f786421-5d75-478e-b6a5-1db964f094d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6248230 entries, 0 to 6248229\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Dtype         \n",
      "---  ------                      -----         \n",
      " 0   type                        object        \n",
      " 1   forum                       object        \n",
      " 2   thread                      object        \n",
      " 3   username                    object        \n",
      " 4   date                        object        \n",
      " 5   content                     object        \n",
      " 6   parsed_date                 datetime64[ns]\n",
      " 7   content_orig                object        \n",
      " 8   netmapper_identity_matches  object        \n",
      "dtypes: datetime64[ns](1), object(8)\n",
      "memory usage: 429.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load data with identity term matches extracted, tokenized\n",
    "import pandas as pd\n",
    "\n",
    "path = '../../data/incels/processed_comments.pkl'\n",
    "# path = '../data/white_supremacist_identities.pkl'\n",
    "data = pd.read_pickle(path)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "101ae0ab-1b43-475f-a939-97129093328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f24f326-600c-4c4b-9889-c2d254fb6ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>forum</th>\n",
       "      <th>thread</th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>parsed_date</th>\n",
       "      <th>content_orig</th>\n",
       "      <th>netmapper_identity_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>COMMENT</td>\n",
       "      <td>001-MustReadContent</td>\n",
       "      <td>0000014-Itssosadthatwereplacesoc</td>\n",
       "      <td>THE TRUE HONKLER</td>\n",
       "      <td>Nov 20, 2020</td>\n",
       "      <td>frothysolutions said : do we ? in order to have this as a replacement for socializing , we have to want to be here . fag we were forced here by foids and lack of any other choice</td>\n",
       "      <td>2020-11-20</td>\n",
       "      <td>FrothySolutions said: Do we? In order to have this as a replacement for socializing, we have to want to be here. fag we were forced here by foids and lack of any other choice</td>\n",
       "      <td>[fag]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type                forum                            thread  \\\n",
       "12  COMMENT  001-MustReadContent  0000014-Itssosadthatwereplacesoc   \n",
       "\n",
       "            username          date  \\\n",
       "12  THE TRUE HONKLER  Nov 20, 2020   \n",
       "\n",
       "                                                                                                                                                                               content  \\\n",
       "12  frothysolutions said : do we ? in order to have this as a replacement for socializing , we have to want to be here . fag we were forced here by foids and lack of any other choice   \n",
       "\n",
       "   parsed_date  \\\n",
       "12  2020-11-20   \n",
       "\n",
       "                                                                                                                                                                      content_orig  \\\n",
       "12  FrothySolutions said: Do we? In order to have this as a replacement for socializing, we have to want to be here. fag we were forced here by foids and lack of any other choice   \n",
       "\n",
       "   netmapper_identity_matches  \n",
       "12                      [fag]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp = data[data.netmapper_identity_matches.map(lambda x: len(x) > 0)].head(1)\n",
    "samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fdf8b07-4c34-4481-9b12-4ef2dc8e42b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "test = test.loc[12, 'content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fee9c6f-5541-4ec2-9e4e-e081ba8ad863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frothysolutions said : do we ? in order to have this as a replacement for socializing , we have to want to be here . fag we were forced here by foids and lack of any other choice"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(test)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d9e447d-3986-4402-92ed-5cfa796e233e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nsubj',\n",
       " 'ROOT',\n",
       " 'punct',\n",
       " 'xcomp',\n",
       " 'nsubj',\n",
       " 'punct',\n",
       " 'prep',\n",
       " 'pobj',\n",
       " 'aux',\n",
       " 'acl',\n",
       " 'dobj',\n",
       " 'prep',\n",
       " 'det',\n",
       " 'pobj',\n",
       " 'prep',\n",
       " 'pobj',\n",
       " 'punct',\n",
       " 'nsubj',\n",
       " 'ROOT',\n",
       " 'aux',\n",
       " 'xcomp',\n",
       " 'aux',\n",
       " 'xcomp',\n",
       " 'advmod',\n",
       " 'punct',\n",
       " 'intj',\n",
       " 'nsubjpass',\n",
       " 'auxpass',\n",
       " 'ROOT',\n",
       " 'advmod',\n",
       " 'agent',\n",
       " 'pobj',\n",
       " 'cc',\n",
       " 'conj',\n",
       " 'prep',\n",
       " 'det',\n",
       " 'amod',\n",
       " 'pobj']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse = [tok.dep_ for tok in doc]\n",
    "parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3fdb563-550d-47ca-bdc1-184f6322a5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'intj'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse[tok_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58f8955c-a559-47b4-8cf4-4c96e6988ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forced"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tok.head for tok in doc][tok_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0253340d-523b-415c-b977-756a1be09d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fag': {'actions': [], 'attributes': []}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Match extracted identities to tokens\n",
    "from collections import defaultdict\n",
    "\n",
    "actions_attributes = {} # identity: {'actions': [actions], {'attributes': [attributes]} # replace with separate columns of attributes and actions in exploded df\n",
    "identity_ctr = defaultdict(int) # keep track of how many of this identity I've seen\n",
    "\n",
    "for identity in samp.loc[12, 'netmapper_identity_matches']:\n",
    "    \n",
    "    # Get identity mention locations\n",
    "    mention_idx = [i for i, tok in enumerate(doc) if tok.text==identity]\n",
    "    tok_idx = mention_idx[identity_ctr[identity]]\n",
    "    \n",
    "    # Verbs where identity term was the subject\n",
    "    verbs_subj = [tok.head.text for tok in doc if tok.i==tok_idx \\\n",
    "        in mention_idx and (tok.dep_=='nsubj' or tok.dep_=='agent')]\n",
    "\n",
    "    # Verbs where identity term was the object\n",
    "    verbs_obj = [tok.head.text for tok in doc if tok.i==tok_idx and \\\n",
    "        (tok.dep_=='dobj' or tok.dep_=='nsubjpass' or \\\n",
    "        tok.dep_=='dative' or tok.dep_=='pobj')]\n",
    "\n",
    "    # Adjectives that describe the identity term\n",
    "    adjs = [tok.text.lower() for tok in doc if tok.head.i == tok_idx and \\\n",
    "        (tok.dep_=='amod' or tok.dep_=='appos' or \\\n",
    "        tok.dep_=='nsubj' or tok.dep_=='nmod')] \\\n",
    "        + [tok.text.lower() for tok in doc if tok.dep_=='attr' and \\\n",
    "            (tok.head.text=='is' or tok.head.text=='was') and \\\n",
    "           any([c.i==tok_idx for c in tok.head.children])]\n",
    "    \n",
    "    actions_attributes[identity] = {'actions': verbs_subj + verbs_obj, 'attributes': adjs}\n",
    "    identity_ctr[identity] += 1\n",
    "    \n",
    "actions_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d63bd2e-c76e-4ffd-9dc5-03a29efde297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 []\n",
       "1                                 []\n",
       "2                                 []\n",
       "3                                 []\n",
       "4                                 []\n",
       "                     ...            \n",
       "6248225    [incels, teenager, teens]\n",
       "6248226                           []\n",
       "6248227                           []\n",
       "6248228            [parenting, kids]\n",
       "6248229                     [incels]\n",
       "Name: netmapper_identity_matches, Length: 6248230, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of identity term unique indexes for each identity term list\n",
    "data['netmapper_identity_matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97274b55-e060-4f5c-82ca-d21d6716fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "def unique_term_index(l):\n",
    "    ctr = Counter()\n",
    "    res = []\n",
    "    for term in l:\n",
    "        res.append(ctr[term])\n",
    "        ctr[term] += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d731238-43fb-49de-b6e0-39562a943428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_term_index(['incels', 'incels', 'teen'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faa9fed-c084-45f3-8010-3cfce5d875aa",
   "metadata": {},
   "source": [
    "# Aggregate extracted actions and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6890e407-bec6-40ed-be3e-e030b64434cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6248230 entries, 0 to 6248229\n",
      "Data columns (total 10 columns):\n",
      " #   Column                            Dtype         \n",
      "---  ------                            -----         \n",
      " 0   type                              object        \n",
      " 1   forum                             object        \n",
      " 2   thread                            object        \n",
      " 3   username                          object        \n",
      " 4   date                              object        \n",
      " 5   content                           object        \n",
      " 6   parsed_date                       datetime64[ns]\n",
      " 7   content_orig                      object        \n",
      " 8   netmapper_identity_matches        object        \n",
      " 9   netmapper_identity_matches_spans  object        \n",
      "dtypes: datetime64[ns](1), object(9)\n",
      "memory usage: 476.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load data with extracted actions and attributes\n",
    "import pandas as pd\n",
    "\n",
    "path = '../../data/incels/processed_comments.pkl'\n",
    "data = pd.read_pickle(path)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2226453e-7bc2-411a-bd8c-fe06031f85d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>forum</th>\n",
       "      <th>thread</th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>parsed_date</th>\n",
       "      <th>content_orig</th>\n",
       "      <th>netmapper_identity_matches</th>\n",
       "      <th>netmapper_identity_matches_spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>COMMENT</td>\n",
       "      <td>001-MustReadContent</td>\n",
       "      <td>0000014-Itssosadthatwereplacesoc</td>\n",
       "      <td>THE TRUE HONKLER</td>\n",
       "      <td>Nov 20, 2020</td>\n",
       "      <td>frothysolutions said : do we ? in order to hav...</td>\n",
       "      <td>2020-11-20</td>\n",
       "      <td>FrothySolutions said: Do we? In order to have ...</td>\n",
       "      <td>[fag, foids]</td>\n",
       "      <td>[(117, 120), (144, 149)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>COMMENT</td>\n",
       "      <td>001-MustReadContent</td>\n",
       "      <td>0000014-Itssosadthatwereplacesoc</td>\n",
       "      <td>ChronicPaincel</td>\n",
       "      <td>Nov 20, 2020</td>\n",
       "      <td>we had to . mogged loner said : the older i ge...</td>\n",
       "      <td>2020-11-20</td>\n",
       "      <td>We had to. Mogged Loner said: the older I get ...</td>\n",
       "      <td>[loner]</td>\n",
       "      <td>[(19, 24)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>COMMENT</td>\n",
       "      <td>001-MustReadContent</td>\n",
       "      <td>0000014-Itssosadthatwereplacesoc</td>\n",
       "      <td>TigerFestival</td>\n",
       "      <td>Nov 20, 2020</td>\n",
       "      <td>mogged loner said : i have nt left my house in...</td>\n",
       "      <td>2020-11-20</td>\n",
       "      <td>Mogged Loner said: I havent left my house in a...</td>\n",
       "      <td>[loner, mother]</td>\n",
       "      <td>[(7, 12), (204, 210)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>COMMENT</td>\n",
       "      <td>001-MustReadContent</td>\n",
       "      <td>0000014-Itssosadthatwereplacesoc</td>\n",
       "      <td>Ika-Sama</td>\n",
       "      <td>Nov 20, 2020</td>\n",
       "      <td>tigerfestival said : a week ? i have n't left ...</td>\n",
       "      <td>2020-11-20</td>\n",
       "      <td>TigerFestival said: A Week? I haven't left my ...</td>\n",
       "      <td>[mother]</td>\n",
       "      <td>[(114, 120)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>COMMENT</td>\n",
       "      <td>001-MustReadContent</td>\n",
       "      <td>0000014-Itssosadthatwereplacesoc</td>\n",
       "      <td>FrothySolutions</td>\n",
       "      <td>Nov 20, 2020</td>\n",
       "      <td>the true honkler said : fag we were forced her...</td>\n",
       "      <td>2020-11-20</td>\n",
       "      <td>THE TRUE HONKLER said: fag we were forced here...</td>\n",
       "      <td>[fag, foids]</td>\n",
       "      <td>[(24, 27), (51, 56)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type                forum                            thread  \\\n",
       "12  COMMENT  001-MustReadContent  0000014-Itssosadthatwereplacesoc   \n",
       "19  COMMENT  001-MustReadContent  0000014-Itssosadthatwereplacesoc   \n",
       "20  COMMENT  001-MustReadContent  0000014-Itssosadthatwereplacesoc   \n",
       "21  COMMENT  001-MustReadContent  0000014-Itssosadthatwereplacesoc   \n",
       "23  COMMENT  001-MustReadContent  0000014-Itssosadthatwereplacesoc   \n",
       "\n",
       "            username          date  \\\n",
       "12  THE TRUE HONKLER  Nov 20, 2020   \n",
       "19    ChronicPaincel  Nov 20, 2020   \n",
       "20     TigerFestival  Nov 20, 2020   \n",
       "21          Ika-Sama  Nov 20, 2020   \n",
       "23   FrothySolutions  Nov 20, 2020   \n",
       "\n",
       "                                              content parsed_date  \\\n",
       "12  frothysolutions said : do we ? in order to hav...  2020-11-20   \n",
       "19  we had to . mogged loner said : the older i ge...  2020-11-20   \n",
       "20  mogged loner said : i have nt left my house in...  2020-11-20   \n",
       "21  tigerfestival said : a week ? i have n't left ...  2020-11-20   \n",
       "23  the true honkler said : fag we were forced her...  2020-11-20   \n",
       "\n",
       "                                         content_orig  \\\n",
       "12  FrothySolutions said: Do we? In order to have ...   \n",
       "19  We had to. Mogged Loner said: the older I get ...   \n",
       "20  Mogged Loner said: I havent left my house in a...   \n",
       "21  TigerFestival said: A Week? I haven't left my ...   \n",
       "23  THE TRUE HONKLER said: fag we were forced here...   \n",
       "\n",
       "   netmapper_identity_matches netmapper_identity_matches_spans  \n",
       "12               [fag, foids]         [(117, 120), (144, 149)]  \n",
       "19                    [loner]                       [(19, 24)]  \n",
       "20            [loner, mother]            [(7, 12), (204, 210)]  \n",
       "21                   [mother]                     [(114, 120)]  \n",
       "23               [fag, foids]             [(24, 27), (51, 56)]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['netmapper_identity_matches_spans'].map(lambda x: len(x) > 0)].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af9ee21-35ba-4873-aaae-2ebff6e8eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = data.explode(['netmapper_identity_matches', 'netmapper_identity'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
