{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d40512b7-31df-45f9-95f0-f0992666ebb7",
   "metadata": {},
   "source": [
    "# Dependency parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f786421-5d75-478e-b6a5-1db964f094d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6248230 entries, 0 to 6248229\n",
      "Data columns (total 9 columns):\n",
      " #   Column                      Dtype         \n",
      "---  ------                      -----         \n",
      " 0   type                        object        \n",
      " 1   forum                       object        \n",
      " 2   thread                      object        \n",
      " 3   username                    object        \n",
      " 4   date                        object        \n",
      " 5   content                     object        \n",
      " 6   parsed_date                 datetime64[ns]\n",
      " 7   content_orig                object        \n",
      " 8   netmapper_identity_matches  object        \n",
      "dtypes: datetime64[ns](1), object(8)\n",
      "memory usage: 429.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load data with identity term matches extracted, tokenized\n",
    "import pandas as pd\n",
    "\n",
    "path = '../../data/incels/processed_comments.pkl'\n",
    "# path = '../data/white_supremacist_identities.pkl'\n",
    "data = pd.read_pickle(path)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "101ae0ab-1b43-475f-a939-97129093328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f24f326-600c-4c4b-9889-c2d254fb6ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>forum</th>\n",
       "      <th>thread</th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>parsed_date</th>\n",
       "      <th>content_orig</th>\n",
       "      <th>netmapper_identity_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>COMMENT</td>\n",
       "      <td>001-MustReadContent</td>\n",
       "      <td>0000014-Itssosadthatwereplacesoc</td>\n",
       "      <td>THE TRUE HONKLER</td>\n",
       "      <td>Nov 20, 2020</td>\n",
       "      <td>frothysolutions said : do we ? in order to have this as a replacement for socializing , we have to want to be here . fag we were forced here by foids and lack of any other choice</td>\n",
       "      <td>2020-11-20</td>\n",
       "      <td>FrothySolutions said: Do we? In order to have this as a replacement for socializing, we have to want to be here. fag we were forced here by foids and lack of any other choice</td>\n",
       "      <td>[fag]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       type                forum                            thread  \\\n",
       "12  COMMENT  001-MustReadContent  0000014-Itssosadthatwereplacesoc   \n",
       "\n",
       "            username          date  \\\n",
       "12  THE TRUE HONKLER  Nov 20, 2020   \n",
       "\n",
       "                                                                                                                                                                               content  \\\n",
       "12  frothysolutions said : do we ? in order to have this as a replacement for socializing , we have to want to be here . fag we were forced here by foids and lack of any other choice   \n",
       "\n",
       "   parsed_date  \\\n",
       "12  2020-11-20   \n",
       "\n",
       "                                                                                                                                                                      content_orig  \\\n",
       "12  FrothySolutions said: Do we? In order to have this as a replacement for socializing, we have to want to be here. fag we were forced here by foids and lack of any other choice   \n",
       "\n",
       "   netmapper_identity_matches  \n",
       "12                      [fag]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp = data[data.netmapper_identity_matches.map(lambda x: len(x) > 0)].head(1)\n",
    "samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fdf8b07-4c34-4481-9b12-4ef2dc8e42b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "test = test.loc[12, 'content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fee9c6f-5541-4ec2-9e4e-e081ba8ad863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frothysolutions said : do we ? in order to have this as a replacement for socializing , we have to want to be here . fag we were forced here by foids and lack of any other choice"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(test)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d9e447d-3986-4402-92ed-5cfa796e233e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nsubj',\n",
       " 'ROOT',\n",
       " 'punct',\n",
       " 'xcomp',\n",
       " 'nsubj',\n",
       " 'punct',\n",
       " 'prep',\n",
       " 'pobj',\n",
       " 'aux',\n",
       " 'acl',\n",
       " 'dobj',\n",
       " 'prep',\n",
       " 'det',\n",
       " 'pobj',\n",
       " 'prep',\n",
       " 'pobj',\n",
       " 'punct',\n",
       " 'nsubj',\n",
       " 'ROOT',\n",
       " 'aux',\n",
       " 'xcomp',\n",
       " 'aux',\n",
       " 'xcomp',\n",
       " 'advmod',\n",
       " 'punct',\n",
       " 'intj',\n",
       " 'nsubjpass',\n",
       " 'auxpass',\n",
       " 'ROOT',\n",
       " 'advmod',\n",
       " 'agent',\n",
       " 'pobj',\n",
       " 'cc',\n",
       " 'conj',\n",
       " 'prep',\n",
       " 'det',\n",
       " 'amod',\n",
       " 'pobj']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse = [tok.dep_ for tok in doc]\n",
    "parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3fdb563-550d-47ca-bdc1-184f6322a5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'intj'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse[tok_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58f8955c-a559-47b4-8cf4-4c96e6988ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forced"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tok.head for tok in doc][tok_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0253340d-523b-415c-b977-756a1be09d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fag': {'actions': [], 'attributes': []}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Match extracted identities to tokens\n",
    "from collections import defaultdict\n",
    "\n",
    "actions_attributes = {} # identity: {'actions': [actions], {'attributes': [attributes]} # replace with separate columns of attributes and actions in exploded df\n",
    "identity_ctr = defaultdict(int) # keep track of how many of this identity I've seen\n",
    "\n",
    "for identity in samp.loc[12, 'netmapper_identity_matches']:\n",
    "    \n",
    "    # Get identity mention locations\n",
    "    mention_idx = [i for i, tok in enumerate(doc) if tok.text==identity]\n",
    "    tok_idx = mention_idx[identity_ctr[identity]]\n",
    "    \n",
    "    # Verbs where identity term was the subject\n",
    "    verbs_subj = [tok.head.text for tok in doc if tok.i==tok_idx \\\n",
    "        in mention_idx and (tok.dep_=='nsubj' or tok.dep_=='agent')]\n",
    "\n",
    "    # Verbs where identity term was the object\n",
    "    verbs_obj = [tok.head.text for tok in doc if tok.i==tok_idx and \\\n",
    "        (tok.dep_=='dobj' or tok.dep_=='nsubjpass' or \\\n",
    "        tok.dep_=='dative' or tok.dep_=='pobj')]\n",
    "\n",
    "    # Adjectives that describe the identity term\n",
    "    adjs = [tok.text.lower() for tok in doc if tok.head.i == tok_idx and \\\n",
    "        (tok.dep_=='amod' or tok.dep_=='appos' or \\\n",
    "        tok.dep_=='nsubj' or tok.dep_=='nmod')] \\\n",
    "        + [tok.text.lower() for tok in doc if tok.dep_=='attr' and \\\n",
    "            (tok.head.text=='is' or tok.head.text=='was') and \\\n",
    "           any([c.i==tok_idx for c in tok.head.children])]\n",
    "    \n",
    "    actions_attributes[identity] = {'actions': verbs_subj + verbs_obj, 'attributes': adjs}\n",
    "    identity_ctr[identity] += 1\n",
    "    \n",
    "actions_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d63bd2e-c76e-4ffd-9dc5-03a29efde297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                 []\n",
       "1                                 []\n",
       "2                                 []\n",
       "3                                 []\n",
       "4                                 []\n",
       "                     ...            \n",
       "6248225    [incels, teenager, teens]\n",
       "6248226                           []\n",
       "6248227                           []\n",
       "6248228            [parenting, kids]\n",
       "6248229                     [incels]\n",
       "Name: netmapper_identity_matches, Length: 6248230, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of identity term unique indexes for each identity term list\n",
    "data['netmapper_identity_matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97274b55-e060-4f5c-82ca-d21d6716fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "def unique_term_index(l):\n",
    "    ctr = Counter()\n",
    "    res = []\n",
    "    for term in l:\n",
    "        res.append(ctr[term])\n",
    "        ctr[term] += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d731238-43fb-49de-b6e0-39562a943428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_term_index(['incels', 'incels', 'teen'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faa9fed-c084-45f3-8010-3cfce5d875aa",
   "metadata": {},
   "source": [
    "# Aggregate extracted actions and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6890e407-bec6-40ed-be3e-e030b64434cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6248230 entries, 0 to 6248229\n",
      "Data columns (total 13 columns):\n",
      " #   Column                            Dtype         \n",
      "---  ------                            -----         \n",
      " 0   type                              object        \n",
      " 1   forum                             object        \n",
      " 2   thread                            object        \n",
      " 3   username                          object        \n",
      " 4   date                              object        \n",
      " 5   content                           object        \n",
      " 6   parsed_date                       datetime64[ns]\n",
      " 7   content_orig                      object        \n",
      " 8   netmapper_identity_matches        object        \n",
      " 9   netmapper_identity_matches_spans  object        \n",
      " 10  actions_attributes                object        \n",
      " 11  dep_parse                         object        \n",
      " 12  dep_head                          object        \n",
      "dtypes: datetime64[ns](1), object(12)\n",
      "memory usage: 619.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load data with extracted actions and attributes\n",
    "import pandas as pd\n",
    "\n",
    "path = '../../data/incels/processed_comments.pkl'\n",
    "data = pd.read_pickle(path)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec5b017-f616-4d66-b2e3-df520481fe1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13416057 entries, 0 to 6248229\n",
      "Data columns (total 14 columns):\n",
      " #   Column                            Dtype         \n",
      "---  ------                            -----         \n",
      " 0   type                              object        \n",
      " 1   forum                             object        \n",
      " 2   thread                            object        \n",
      " 3   username                          object        \n",
      " 4   date                              object        \n",
      " 5   content                           object        \n",
      " 6   parsed_date                       datetime64[ns]\n",
      " 7   content_orig                      object        \n",
      " 8   netmapper_identity_matches        object        \n",
      " 9   netmapper_identity_matches_spans  object        \n",
      " 10  actions_attributes                object        \n",
      " 11  dep_parse                         object        \n",
      " 12  dep_head                          object        \n",
      " 13  identity_group                    object        \n",
      "dtypes: datetime64[ns](1), object(13)\n",
      "memory usage: 1.5+ GB\n"
     ]
    }
   ],
   "source": [
    "exp = data.explode(['netmapper_identity_matches', 'actions_attributes'])\n",
    "# exp.info()\n",
    "\n",
    "# Group identities\n",
    "import json\n",
    "\n",
    "identity_groups_fpath = '../resources/identity_groups.json'\n",
    "with open(identity_groups_fpath, 'r') as f:\n",
    "    identity_groups = json.load(f)\n",
    "print(len(identity_groups))\n",
    "\n",
    "exp['identity_group'] = exp.netmapper_identity_matches.map(lambda x: identity_groups.get(x, x))\n",
    "exploded = exp.explode('identity_group') # Count intersectional mentions as a mention in each of their categories\n",
    "exploded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e8ce1-f420-4450-90bb-e02f0d9501c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "samp = exploded.sample(int(1e6))\n",
    "gped = samp.groupby('identity_group')\n",
    "# gped = exploded.groupby('identity_group')\n",
    "\n",
    "# Aggregate actions and attribute for different identities\n",
    "# agg = gped.agg({'content': 'count'})\n",
    "# agg = gped.agg({'actions_attributes': lambda x: {'actions': sum([el['actions'] for el in x], [])}})\n",
    "agg = gped.agg({'actions_attributes': lambda x: {'actions': sum([el['actions'] for el in x], []),\n",
    "                                                'attributes': sum([el['attributes'] for el in x], [])},\n",
    "                                               'content': 'count'\n",
    "                                              })\n",
    "agg.rename(columns = {'content': 'count'}, inplace=True)\n",
    "agg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8a9ce48-f401-43ba-8d26-d75da07e72a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actions_attributes</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identity_group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>women_girls</th>\n",
       "      <td>{'actions': ['count', 'want', 'are', 'finding'...</td>\n",
       "      <td>1938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>men_boys</th>\n",
       "      <td>{'actions': ['over', 'from', 'do', 'off', 're'...</td>\n",
       "      <td>1528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women_girls_derogatory</th>\n",
       "      <td>{'actions': ['with', 'lmfao', 'banned', 'norma...</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incels</th>\n",
       "      <td>{'actions': ['accepting', 'with', 'offtopic', ...</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>men_boys_address</th>\n",
       "      <td>{'actions': ['lol', 'picking', 'see', 'fucking...</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       actions_attributes  \\\n",
       "identity_group                                                              \n",
       "women_girls             {'actions': ['count', 'want', 'are', 'finding'...   \n",
       "men_boys                {'actions': ['over', 'from', 'do', 'off', 're'...   \n",
       "women_girls_derogatory  {'actions': ['with', 'lmfao', 'banned', 'norma...   \n",
       "incels                  {'actions': ['accepting', 'with', 'offtopic', ...   \n",
       "men_boys_address        {'actions': ['lol', 'picking', 'see', 'fucking...   \n",
       "\n",
       "                        count  \n",
       "identity_group                 \n",
       "women_girls              1938  \n",
       "men_boys                 1528  \n",
       "women_girls_derogatory    648  \n",
       "incels                    461  \n",
       "men_boys_address          234  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg.sort_values('count', ascending=False, inplace=True)\n",
    "agg.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3f6ff01-0ac8-48b7-b636-a656ed4b5c3c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actions</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>identity_group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>women_girls</th>\n",
       "      <td>[(with, 85), (are, 75), (get, 45), (have, 38),...</td>\n",
       "      <td>[(white, 18), (fucking, 13), (black, 12), (sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>men_boys</th>\n",
       "      <td>[(are, 47), (have, 38), (with, 35), (is, 32), ...</td>\n",
       "      <td>[(ugly, 30), (white, 27), (most, 19), (other, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women_girls_derogatory</th>\n",
       "      <td>[(are, 23), (with, 21), (get, 14), (like, 13),...</td>\n",
       "      <td>[(white, 8), (dumb, 7), (young, 7), (foid, 7),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incels</th>\n",
       "      <td>[(are, 22), (as, 20), (said, 10), (about, 7), ...</td>\n",
       "      <td>[(incel, 12), (many, 4), (white, 3), (most, 3)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>men_boys_address</th>\n",
       "      <td>[(is, 4), (get, 3), (looks, 3), (fucking, 2), ...</td>\n",
       "      <td>[(good, 4), (other, 3), (random, 3), (looking,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  actions  \\\n",
       "identity_group                                                              \n",
       "women_girls             [(with, 85), (are, 75), (get, 45), (have, 38),...   \n",
       "men_boys                [(are, 47), (have, 38), (with, 35), (is, 32), ...   \n",
       "women_girls_derogatory  [(are, 23), (with, 21), (get, 14), (like, 13),...   \n",
       "incels                  [(are, 22), (as, 20), (said, 10), (about, 7), ...   \n",
       "men_boys_address        [(is, 4), (get, 3), (looks, 3), (fucking, 2), ...   \n",
       "\n",
       "                                                               attributes  \n",
       "identity_group                                                             \n",
       "women_girls             [(white, 18), (fucking, 13), (black, 12), (sin...  \n",
       "men_boys                [(ugly, 30), (white, 27), (most, 19), (other, ...  \n",
       "women_girls_derogatory  [(white, 8), (dumb, 7), (young, 7), (foid, 7),...  \n",
       "incels                  [(incel, 12), (many, 4), (white, 3), (most, 3)...  \n",
       "men_boys_address        [(good, 4), (other, 3), (random, 3), (looking,...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make counters for associated words with identity group terms\n",
    "from collections import Counter\n",
    "\n",
    "agg['actions'] = agg.actions_attributes.map(lambda x: Counter(x['actions']).most_common())\n",
    "agg['attributes'] = agg.actions_attributes.map(lambda x: Counter(x['attributes']).most_common())\n",
    "agg[['actions', 'attributes']].head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
